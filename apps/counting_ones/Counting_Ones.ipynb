{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating training  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "NUM_EXAMPLES = 2 ** 20\n",
    "\n",
    "data_input = ['{0:020b}'.format(i) for i in range (NUM_EXAMPLES)]\n",
    "shuffle(data_input)\n",
    "data_input = [map(int, i) for i in data_input]\n",
    "ti = []\n",
    "for i in data_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "        temp_list.append([j])\n",
    "    ti.append(np.array(temp_list)) \n",
    "data_input = ti    \n",
    "\n",
    "data_output = []\n",
    "\n",
    "for i in data_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*21)\n",
    "    temp_list[count] = 1\n",
    "    data_output.append(temp_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training inputs 209715\n",
      "# of validation inputs 104857\n",
      "# of inputs 1048576\n",
      "# of training inputs 209715\n",
      "# of validation inputs 104857\n",
      "# of test inputs 734004\n"
     ]
    }
   ],
   "source": [
    "SIZE_TRAINING = int(0.2 * NUM_EXAMPLES)\n",
    "SIZE_VALIDATION_SET = int(0.1 * NUM_EXAMPLES)\n",
    "print(\"# of training inputs {}\".format(SIZE_TRAINING))\n",
    "print(\"# of validation inputs {}\".format(SIZE_VALIDATION_SET))\n",
    "\n",
    "train_input = data_input[:SIZE_TRAINING]\n",
    "train_output= data_output[:SIZE_TRAINING]\n",
    "\n",
    "validation_input = data_input[SIZE_TRAINING: SIZE_TRAINING + SIZE_VALIDATION_SET]\n",
    "validation_output= data_output[SIZE_TRAINING: SIZE_TRAINING + SIZE_VALIDATION_SET]\n",
    "\n",
    "test_input = data_input[SIZE_TRAINING + SIZE_VALIDATION_SET:]\n",
    "test_output = data_output[SIZE_TRAINING + SIZE_VALIDATION_SET:]\n",
    "print(\"# of inputs {}\".format(len(data_input)))\n",
    "print (\"# of training inputs {}\".format(len(train_input)))\n",
    "print (\"# of validation inputs {}\".format(len(validation_input)))\n",
    "print (\"# of test inputs {}\".format(len(test_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raman/anaconda/envs/ml/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data = tf.placeholder(tf.float32, [None, 20, 1])\n",
    "target = tf.placeholder(tf.float32, [None, 21])\n",
    "\n",
    "num_hidden = 24\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple = True)\n",
    "\n",
    "val, state = tf.nn.dynamic_rnn(cell, data, dtype = tf.float32)\n",
    "val = tf.transpose(val, [1, 0, 2])\n",
    "last = tf.gather(val, int(val.get_shape()[0]) - 1)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([num_hidden, int(target.get_shape()[1])]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[target.get_shape()[1]]))\n",
    "logits = tf.matmul(last, weight) + bias\n",
    "prediction = tf.nn.softmax(logits)\n",
    "cross_entropy = -tf.reduce_sum(target * tf.log(tf.clip_by_value(prediction, 1e010, 1.0)))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calclulation of Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(target, 1), tf.argmax(prediction, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-c4b450693cc3>:3 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch - 10, error 1.0%\n",
      "Epoch - 20, error 1.0%\n",
      "Epoch - 30, error 1.0%\n",
      "Epoch - 40, error 1.0%\n",
      "Epoch 50 completed\n",
      "Epoch 50 error 99.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "\n",
    "batch_size = 1000\n",
    "n_batches = int(len(train_input)/batch_size)\n",
    "n_epochs = 50\n",
    "\n",
    "'''\n",
    "def evaluate(X, Y):\n",
    "    n_input = len(X)\n",
    "    session = tf.get_default_session()\n",
    "    total_accuracy = 0\n",
    "    for offset in range(0, n_input, batch_size):\n",
    "        batch_end = offset + BATCH_SIZE\n",
    "        x_batch, y_batch = X_data[offset: batch_end], y_data[offset: batch_end]\n",
    "        accuracy = session.run(accuracy_operation, feed_dict = {x: x_batch, y: y_batch})\n",
    "        total_accuracy += (accuracy * len(x_batch))\n",
    "    return total_accuracy/n_input\n",
    "'''\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)    \n",
    "    for i in range(n_epochs):\n",
    "        #train_input, train_output = shuffle(train_input, train_output)\n",
    "        for j in range(n_batches):\n",
    "            begin = j * batch_size\n",
    "            end = begin + batch_size\n",
    "            batch_input, batch_output = train_input[begin: end], train_output[begin: end]\n",
    "            sess.run(minimize, feed_dict = {data: batch_input, target: batch_output})\n",
    "        if i is not 0 and i % 10 == 0:\n",
    "            validation_error = sess.run(error, feed_dict = {data: validation_input, target: validation_output})\n",
    "            print (\"Epoch - {}, error {:3.1f}%\".format(str(i), validation_error))\n",
    "    print(\"Epoch {:2d} completed\".format(i + 1))\n",
    "    test_error = sess.run(error, feed_dict = {data: test_input, target: test_output}) \n",
    "    print(\"Epoch {:2d} error {:3.1f}%\".format(i+1, 100 * test_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
